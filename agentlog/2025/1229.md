

## Session: Remote Worker Deployment & Database Sync (2025-12-29)

> Deploy remote worker to RTX4090-Station and fix database synchronization for distributed workers.

<details>
<summary>Fixed multiple worker bugs and implemented Redis pub/sub sync for experiment results</summary>

### Phase 1: Remote Worker Bug Fixes

#### Conversation 1.1: LocalGPUInfo Property Errors

**User**: Run SGLang tuning task on RTX4090-Station

**Issues Encountered**:
```
'LocalGPUInfo' object has no attribute 'utilization_percent'
'LocalGPUInfo' object has no attribute 'temperature_c'
```

**Root Cause**: The `LocalGPUInfo` dataclass in `gpu_types.py` was missing property aliases that `LocalController` expected.

**Fix in `src/utils/gpu_types.py`**:
```python
@property
def memory_usage_percent(self) -> float:
    """Memory usage percentage (for backward compatibility)."""
    if self.memory_total_mb == 0:
        return 0.0
    return (self.memory_used_mb / self.memory_total_mb) * 100

@property
def utilization_percent(self) -> int:
    """GPU utilization percentage (alias for utilization_gpu)."""
    return self.utilization_gpu

@property
def temperature_c(self) -> Optional[int]:
    """GPU temperature in Celsius (alias for temperature)."""
    return self.temperature

@property
def is_available(self) -> bool:
    """Check if GPU is available for allocation (has free memory)."""
    return self.memory_free_mb > 1000  # At least 1GB free
```

---

#### Conversation 1.2: Import Error in base_controller.py

**Issue**: `ImportError: attempted relative import beyond top-level package`

**Root Cause**: `base_controller.py` used relative import `from ..utils.gpu_monitor` but when run by ARQ worker, the package structure was different.

**Fix**: Changed `from ..utils.gpu_monitor` to `from utils.gpu_monitor` in base_controller.py.

---

#### Conversation 1.3: Python Cache Issues

**Issue**: Code changes were synced but not taking effect on remote worker.

**Root Cause**: Python `__pycache__` directories contained stale bytecode.

**Fix**: `find /root/work/inference-autotuner -type d -name __pycache__ -exec rm -rf {} +`

---

#### Conversation 1.4: Redis Connectivity

**Issue**: Remote worker connecting to wrong Redis (local docker Redis on 6379 instead of manager Redis via SSH tunnel on 16379).

**Fix**: Updated `.env` on remote with `REDIS_PORT=16379`

---

#### Conversation 1.5: GPU Occupancy

**Issue**: All 8 GPUs on RTX4090-Station showing 94-97% utilization from existing containers.

**Fix**: Stopped `br_test_1` to free GPU0 for task execution.

---

#### Conversation 1.6: ARQ Job Queue Stale Markers

**Issue**: Job stuck in queue with stale `in-progress` marker from previous failed attempts.

**Fix**: Cleared stale ARQ keys from Redis.

**Result**: Task 45 started executing successfully on remote worker.

---

### Phase 2: Database Sync Issue

#### Conversation 2.1: Experiments Not Showing

**User**: Why does task 45 show experiments=0/0 when logs show it's running successfully?

**Root Cause Analysis**:
1. SQLite is a single-machine database
2. Worker on remote machine updates the **remote** SQLite database
3. API on local machine queries the **local** SQLite database
4. No synchronization between the two databases

**Proposed Solutions**:
1. Use PostgreSQL/MySQL as shared database
2. **Use Redis pub/sub to sync experiment results** (selected by user)

---

### Phase 3: Implementing Redis Pub/Sub Database Sync

#### Solution Design

The existing infrastructure already has:
- `ResultPublisher` in `pubsub.py` - Workers publish experiment results
- `ResultListener` in `result_listener.py` - Manager subscribes to results

**Missing**: The callback that updates the local database when results are received.

#### Implementation in `src/web/app.py`

Added `sync_experiment_to_local_db()` function that:
1. Receives `ExperimentResult` from Redis Pub/Sub
2. Checks if task exists in local database
3. Creates or updates experiment record
4. Updates task counters (total_experiments, successful_experiments, best_experiment_id)

**sync_experiment_to_local_db() code**:
```python
async def sync_experiment_to_local_db(result: ExperimentResult) -> bool:
    """Sync experiment result from remote worker to local database."""
    async with AsyncSessionLocal() as db:
        # Check if task exists locally
        task = await db.execute(select(Task).where(Task.id == result.task_id))

        # Check if experiment already exists
        experiment = await db.execute(
            select(Experiment).where(
                Experiment.task_id == result.task_id,
                Experiment.experiment_id == result.experiment_id
            )
        )

        if experiment:
            # Update existing experiment
            experiment.status = exp_status
            experiment.metrics = result.metrics
            experiment.objective_score = result.objective_score
            ...
        else:
            # Create new experiment
            experiment = Experiment(
                task_id=result.task_id,
                experiment_id=result.experiment_id,
                parameters=result.parameters,
                ...
            )
            db.add(experiment)

        # Update task counters
        await db.execute(
            update(Task).where(Task.id == result.task_id).values(
                total_experiments=total,
                successful_experiments=successful,
                best_experiment_id=best_exp_id,
            )
        )
```

**Modified on_result callback**:
```python
async def on_result(result: ExperimentResult):
    """Handle experiment result from distributed workers."""
    logger.info(f"Received result via Pub/Sub: task={result.task_id} ...")
    synced = await sync_experiment_to_local_db(result)
    if synced:
        logger.info(f"Synced experiment to local database")
```

---

### Files Modified

| File | Changes |
|------|---------|
| `src/utils/gpu_types.py` | Added property aliases for backward compatibility |
| `src/controllers/base_controller.py` | Fixed import path |
| `src/web/app.py` | Added `sync_experiment_to_local_db()` and enhanced `on_result` callback |

---

### Phase 4: Additional Bug Fixes

#### Issue: NoneType Error for Remote Workers

**Error**: `AttributeError: 'NoneType' object has no attribute 'successful_experiments'`

**Root Cause**: The worker code assumed `task` would always be a valid database object, but remote workers don't have database access (SQLite is local to manager).

**Fix in `src/web/workers/autotuner_worker.py`**:
```python
# Before
if result["status"] == "success":
    task.successful_experiments += 1  # Fails when task is None

# After
if result["status"] == "success":
    if task:
        task.successful_experiments += 1  # Safe check
```

---

### Phase 5: Successful Sync Test

**Task 50** (`sync-test-v12`) completed successfully on remote worker RTX4090-Station:

| Metric | Value |
|--------|-------|
| Total Throughput | 2488 tokens/s |
| E2E Latency (mean) | 41.6ms |
| TTFT (mean) | 14.7ms |
| Requests Completed | 68 |
| Success Rate | 100% |

**Result**: Experiment data was successfully synced from remote worker to local database via Redis Pub/Sub:
- `total_experiments`: 1
- `successful_experiments`: 1
- `best_experiment_id`: 336
- Full metrics and parameters stored

---

### Files Modified (Final)

| File | Changes |
|------|---------|
| `src/utils/gpu_types.py` | Added property aliases for backward compatibility |
| `src/controllers/base_controller.py` | Fixed import path |
| `src/web/app.py` | Added `sync_experiment_to_local_db()` and enhanced `on_result` callback |
| `src/web/workers/autotuner_worker.py` | Added null check for task object |

---

### Summary

Successfully deployed distributed worker architecture:
1. Remote worker on RTX4090-Station processes Docker-based tuning tasks
2. Results published via Redis Pub/Sub
3. Manager receives and syncs results to local SQLite database
4. Frontend/API shows complete experiment data from remote executions

</details>

---

