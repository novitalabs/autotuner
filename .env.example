# Backend Configuration
DATABASE_URL=sqlite+aiosqlite:////home/user/.local/share/inference-autotuner/autotuner.db
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DOCKER_MODEL_PATH=/mnt/data/models

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
FRONTEND_PORT=5173

# Timezone
TIMEZONE=UTC

# Frontend Configuration
# Leave empty to use relative URLs (works with Vite proxy and port forwarding)
VITE_API_URL=

# GitHub repository for update checking (format: owner/repo)
VITE_GITHUB_REPO=novitalabs/inference-autotuner

# Network Proxy (for Docker containers to reach HuggingFace)
# Uncomment and configure if you're behind a proxy
# HTTP_PROXY=http://172.17.0.1:1081
# HTTPS_PROXY=http://172.17.0.1:1081
NO_PROXY=localhost,127.0.0.1

# HuggingFace Token (for gated models like Llama)
# Get token from: https://huggingface.co/settings/tokens
HF_TOKEN=

# Agent Configuration
# Providers: local, claude, openai, jiekou
AGENT_PROVIDER=local
AGENT_BASE_URL=http://localhost:8000/v1
AGENT_MODEL=llama-3-70b-instruct
AGENT_API_KEY=

# For Claude provider:
# AGENT_PROVIDER=claude
# AGENT_BASE_URL=https://api.anthropic.com
# AGENT_MODEL=claude-sonnet-4-20250514
# AGENT_API_KEY=sk-ant-...

# GitHub Integration (for Agent issue tracking)
# Get token from: https://github.com/settings/tokens
GH_TOKEN=
GH_REPO=owner/repo
